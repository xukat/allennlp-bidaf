structure of squad data

data = json.load(open(path_to_data))

context: data['data'][article_no]['paragraphs'][paragraph_no]['context']
-> string

qas: data['data'][article_no]['paragraphs'][paragraph_no]['qas']
-> list of qas associated with the context
-> each element is dict with keys "answers" "question" and "id"
--> answers is a list of dicts with keys "answer_start" and "text"
--> question is a string
--> id is a string

Todo
Get logits from bert to bidaf
	Save data
	Modify data reader
Add loss function to bidafdistill class
Add gpu support ?
Train 


# batch size = 8
# Pretrained model: start_acc: 0.30, end_acc: 0.31, span_acc: 0.20, em: 0.27, f1: 0.41, loss: 7.04 ||: : 1322it [05:46,  3.82it/s]
# Trained one epoch: start_acc: 0.53, end_acc: 0.57, span_acc: 0.44, em: 0.53, f1: 0.65, loss: 3.39 ||: : 1322it [05:57,  3.70it/s]

# batch size = 32
# pretrained: start_acc: 0.30, end_acc: 0.31, span_acc: 0.20, em: 0.27, f1: 0.41, loss: 7.04 ||: : 331it [05:41,  1.03s/it]
# trained one epoch: start_acc: 0.54, end_acc: 0.58, span_acc: 0.46, em: 0.57, f1: 0.67, loss: 3.19 ||: : 331it [03:52,  1.42it/s]

folder : train-5-epoch
	train epoch 2:	start_acc: 0.5822, end_acc: 0.6326, span_acc: 0.4911, em: 0.5429, f1: 0.6811, batch_loss: 2.7388, loss: 2.7273 ||: 100%|##########| 2738/2738 [10:53:41<00:00, 14.32s/it]
	val epoch 2:	start_acc: 0.5535, end_acc: 0.5924, span_acc: 0.4696, em: 0.5827, f1: 0.6878, batch_loss: 3.7573, loss: 3.1853 ||: 100%|##########| 331/331 [04:15<00:00,  1.30it/s]
	
	train epoch 3:	start_acc: 0.6046, end_acc: 0.6549, span_acc: 0.5133, em: 0.5663, f1: 0.7039, batch_loss: 3.8442, loss: 2.5290 ||: 100%|##########| 2738/2738 [6:44:36<00:00,  8.87s/it]
	val epoch 3:	start_acc: 0.5552, end_acc: 0.5897, span_acc: 0.4715, em: 0.5842, f1: 0.6860, batch_loss: 3.8719, loss: 3.1517 ||: 100%|##########| 331/331 [04:19<00:00,  1.27it/s]
	
	train epoch 4:	start_acc: 0.6204, end_acc: 0.6746, span_acc: 0.5297, em: 0.5825, f1: 0.7216, batch_loss: 2.1268, loss: 2.3737 ||: 100%|##########| 2738/2738 [6:44:20<00:00,  8.86s/it]
	val epoch 4:	start_acc: 0.5496, end_acc: 0.5938, span_acc: 0.4696, em: 0.5798, f1: 0.6840, batch_loss: 5.1634, loss: 3.2744 ||: 100%|##########| 331/331 [04:23<00:00,  1.26it/s]
	
	train epoch 5:	start_acc: 0.6363, end_acc: 0.6908, span_acc: 0.5457, em: 0.5997, f1: 0.7377, batch_loss: 0.9865, loss: 2.2416 ||: 100%|##########| 2738/2738 [6:45:06<00:00,  8.88s/it]
	val epoch 5:	start_acc: 0.5535, end_acc: 0.5904, span_acc: 0.4690, em: 0.5807, f1: 0.6851, batch_loss: 5.3856, loss: 3.2990 ||: 100%|##########| 331/331 [04:20<00:00,  1.27it/s]

train with distill 5 epoch - temp = 1; distill weight = 1;
## epoch 1
start_acc: 0.5142, end_acc: 0.5470, span_acc: 0.4153, em: 0.4565, f1: 0.5936, batch_loss: 11.2980, loss: 12.5784 ||: 100%|##########| 2700/2700 [11:19<00:00,  3.97it/s]
start_acc: 0.5358, end_acc: 0.5745, span_acc: 0.4531, em: 0.5602, f1: 0.6667, batch_loss: 5.1534, loss: 4.4159 ||: 100%|##########| 331/331 [00:26<00:00, 12.46it/s]

## epoch 2
start_acc: 0.5569, end_acc: 0.5949, span_acc: 0.4599, em: 0.5023, f1: 0.6416, batch_loss: 12.5898, loss: 11.5461 ||: 100%|##########| 2700/2700 [11:20<00:00,  3.97it/s]
start_acc: 0.5465, end_acc: 0.5789, span_acc: 0.4576, em: 0.5660, f1: 0.6800, batch_loss: 5.8653, loss: 4.2617 ||: 100%|##########| 331/331 [00:26<00:00, 12.53it/s]

## epoch 3
start_acc: 0.5762, end_acc: 0.6182, span_acc: 0.4809, em: 0.5242, f1: 0.6644, batch_loss: 11.4257, loss: 11.0998 ||: 100%|##########| 2700/2700 [11:19<00:00,  3.97it/s]
start_acc: 0.5518, end_acc: 0.5877, span_acc: 0.4694, em: 0.5742, f1: 0.6767, batch_loss: 5.6370, loss: 4.2890 ||: 100%|##########| 331/331 [00:26<00:00, 12.48it/s]

## epoch 4
start_acc: 0.5906, end_acc: 0.6325, span_acc: 0.4927, em: 0.5358, f1: 0.6784, batch_loss: 11.9925, loss: 10.7656 ||: 100%|##########| 2700/2700 [11:20<00:00,  3.97it/s]
start_acc: 0.5480, end_acc: 0.5874, span_acc: 0.4683, em: 0.5741, f1: 0.6811, batch_loss: 5.1599, loss: 4.3201 ||: 100%|##########| 331/331 [00:26<00:00, 12.59it/s]

## epoch 5
start_acc: 0.6017, end_acc: 0.6448, span_acc: 0.5048, em: 0.5484, f1: 0.6905, batch_loss: 8.5322, loss: 10.5064 ||: 100%|##########| 2700/2700 [11:17<00:00,  3.99it/s]
start_acc: 0.5476, end_acc: 0.5800, span_acc: 0.4619, em: 0.5653, f1: 0.6772, batch_loss: 5.6528, loss: 4.3790 ||: 100%|##########| 331/331 [00:26<00:00, 12.51it/s]


