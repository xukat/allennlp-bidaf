structure of squad data

data = json.load(open(path_to_data))

context: data['data'][article_no]['paragraphs'][paragraph_no]['context']
-> string

qas: data['data'][article_no]['paragraphs'][paragraph_no]['qas']
-> list of qas associated with the context
-> each element is dict with keys "answers" "question" and "id"
--> answers is a list of dicts with keys "answer_start" and "text"
--> question is a string
--> id is a string

Todo
Get logits from bert to bidaf
	Save data
	Modify data reader
Add loss function to bidafdistill class
Add gpu support ?
Train 


# batch size = 8
# Pretrained model: start_acc: 0.30, end_acc: 0.31, span_acc: 0.20, em: 0.27, f1: 0.41, loss: 7.04 ||: : 1322it [05:46,  3.82it/s]
# Trained one epoch: start_acc: 0.53, end_acc: 0.57, span_acc: 0.44, em: 0.53, f1: 0.65, loss: 3.39 ||: : 1322it [05:57,  3.70it/s]

# batch size = 32
# pretrained: start_acc: 0.30, end_acc: 0.31, span_acc: 0.20, em: 0.27, f1: 0.41, loss: 7.04 ||: : 331it [05:41,  1.03s/it]
# trained one epoch: start_acc: 0.54, end_acc: 0.58, span_acc: 0.46, em: 0.57, f1: 0.67, loss: 3.19 ||: : 331it [03:52,  1.42it/s]

folder : train-5-epoch
	train epoch 2:	start_acc: 0.5822, end_acc: 0.6326, span_acc: 0.4911, em: 0.5429, f1: 0.6811, batch_loss: 2.7388, loss: 2.7273 ||: 100%|##########| 2738/2738 [10:53:41<00:00, 14.32s/it]
	val epoch 2:	start_acc: 0.5535, end_acc: 0.5924, span_acc: 0.4696, em: 0.5827, f1: 0.6878, batch_loss: 3.7573, loss: 3.1853 ||: 100%|##########| 331/331 [04:15<00:00,  1.30it/s]
	
	train epoch 3:	start_acc: 0.6046, end_acc: 0.6549, span_acc: 0.5133, em: 0.5663, f1: 0.7039, batch_loss: 3.8442, loss: 2.5290 ||: 100%|##########| 2738/2738 [6:44:36<00:00,  8.87s/it]
	val epoch 3:	start_acc: 0.5552, end_acc: 0.5897, span_acc: 0.4715, em: 0.5842, f1: 0.6860, batch_loss: 3.8719, loss: 3.1517 ||: 100%|##########| 331/331 [04:19<00:00,  1.27it/s]
	
	train epoch 4:	start_acc: 0.6204, end_acc: 0.6746, span_acc: 0.5297, em: 0.5825, f1: 0.7216, batch_loss: 2.1268, loss: 2.3737 ||: 100%|##########| 2738/2738 [6:44:20<00:00,  8.86s/it]
	val epoch 4:	start_acc: 0.5496, end_acc: 0.5938, span_acc: 0.4696, em: 0.5798, f1: 0.6840, batch_loss: 5.1634, loss: 3.2744 ||: 100%|##########| 331/331 [04:23<00:00,  1.26it/s]
	
	train epoch 5:	start_acc: 0.6363, end_acc: 0.6908, span_acc: 0.5457, em: 0.5997, f1: 0.7377, batch_loss: 0.9865, loss: 2.2416 ||: 100%|##########| 2738/2738 [6:45:06<00:00,  8.88s/it]
	val epoch 5:	start_acc: 0.5535, end_acc: 0.5904, span_acc: 0.4690, em: 0.5807, f1: 0.6851, batch_loss: 5.3856, loss: 3.2990 ||: 100%|##########| 331/331 [04:20<00:00,  1.27it/s]

train with distill 5 epoch - temp = 1; distill weight = 1;
## epoch 1
start_acc: 0.5142, end_acc: 0.5470, span_acc: 0.4153, em: 0.4565, f1: 0.5936, batch_loss: 11.2980, loss: 12.5784 ||: 100%|##########| 2700/2700 [11:19<00:00,  3.97it/s]
start_acc: 0.5358, end_acc: 0.5745, span_acc: 0.4531, em: 0.5602, f1: 0.6667, batch_loss: 5.1534, loss: 4.4159 ||: 100%|##########| 331/331 [00:26<00:00, 12.46it/s]

## epoch 2
start_acc: 0.5569, end_acc: 0.5949, span_acc: 0.4599, em: 0.5023, f1: 0.6416, batch_loss: 12.5898, loss: 11.5461 ||: 100%|##########| 2700/2700 [11:20<00:00,  3.97it/s]
start_acc: 0.5465, end_acc: 0.5789, span_acc: 0.4576, em: 0.5660, f1: 0.6800, batch_loss: 5.8653, loss: 4.2617 ||: 100%|##########| 331/331 [00:26<00:00, 12.53it/s]

## epoch 3
start_acc: 0.5762, end_acc: 0.6182, span_acc: 0.4809, em: 0.5242, f1: 0.6644, batch_loss: 11.4257, loss: 11.0998 ||: 100%|##########| 2700/2700 [11:19<00:00,  3.97it/s]
start_acc: 0.5518, end_acc: 0.5877, span_acc: 0.4694, em: 0.5742, f1: 0.6767, batch_loss: 5.6370, loss: 4.2890 ||: 100%|##########| 331/331 [00:26<00:00, 12.48it/s]

## epoch 4
start_acc: 0.5906, end_acc: 0.6325, span_acc: 0.4927, em: 0.5358, f1: 0.6784, batch_loss: 11.9925, loss: 10.7656 ||: 100%|##########| 2700/2700 [11:20<00:00,  3.97it/s]
start_acc: 0.5480, end_acc: 0.5874, span_acc: 0.4683, em: 0.5741, f1: 0.6811, batch_loss: 5.1599, loss: 4.3201 ||: 100%|##########| 331/331 [00:26<00:00, 12.59it/s]

## epoch 5
start_acc: 0.6017, end_acc: 0.6448, span_acc: 0.5048, em: 0.5484, f1: 0.6905, batch_loss: 8.5322, loss: 10.5064 ||: 100%|##########| 2700/2700 [11:17<00:00,  3.99it/s]
start_acc: 0.5476, end_acc: 0.5800, span_acc: 0.4619, em: 0.5653, f1: 0.6772, batch_loss: 5.6528, loss: 4.3790 ||: 100%|##########| 331/331 [00:26<00:00, 12.51it/s]


train with distill 5 epoch - temp = 10; distill weight = 1;

start_acc: 0.5153, end_acc: 0.5476, span_acc: 0.4142, em: 0.4569, f1: 0.5956, batch_loss: 1003.4037, loss: 973.3224 ||: 100%|##########| 2700/2700 [11:22<00:00,  3.96it/s]
start_acc: 0.5408, end_acc: 0.5767, span_acc: 0.4561, em: 0.5676, f1: 0.6731, batch_loss: 6.3630, loss: 4.0334 ||: 100%|##########| 331/331 [00:26<00:00, 12.55it/s]

start_acc: 0.5613, end_acc: 0.5980, span_acc: 0.4619, em: 0.5058, f1: 0.6445, batch_loss: 956.7521, loss: 971.8626 ||: 100%|##########| 2700/2700 [11:21<00:00,  3.96it/s]
start_acc: 0.5490, end_acc: 0.5868, span_acc: 0.4611, em: 0.5752, f1: 0.6847, batch_loss: 5.4939, loss: 3.9802 ||: 100%|##########| 331/331 [00:26<00:00, 12.59it/s]

start_acc: 0.5846, end_acc: 0.6243, span_acc: 0.4869, em: 0.5308, f1: 0.6707, batch_loss: 965.0767, loss: 971.2574 ||: 100%|##########| 2700/2700 [11:17<00:00,  3.98it/s]
start_acc: 0.5466, end_acc: 0.5860, span_acc: 0.4616, em: 0.5797, f1: 0.6857, batch_loss: 9.5399, loss: 4.0396 ||: 100%|##########| 331/331 [00:26<00:00, 12.54it/s]

start_acc: 0.6015, end_acc: 0.6429, span_acc: 0.5040, em: 0.5476, f1: 0.6876, batch_loss: 959.2438, loss: 970.8427 ||: 100%|##########| 2700/2700 [11:27<00:00,  3.93it/s]
start_acc: 0.5493, end_acc: 0.5820, span_acc: 0.4577, em: 0.5739, f1: 0.6848, batch_loss: 12.1510, loss: 4.1596 ||: 100%|##########| 331/331 [00:26<00:00, 12.57it/s]

start_acc: 0.6126, end_acc: 0.6553, span_acc: 0.5140, em: 0.5573, f1: 0.6981, batch_loss: 1017.8574, loss: 970.5535 ||: 100%|##########| 2700/2700 [11:19<00:00,  3.97it/s]
start_acc: 0.5516, end_acc: 0.5874, span_acc: 0.4660, em: 0.5778, f1: 0.6878, batch_loss: 11.0433, loss: 4.1520 ||: 100%|##########| 331/331 [00:26<00:00, 12.55it/s]

_text_field_embedder.token_embedder_token_characters._embedding._module.weight True
_text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight True
_text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias True
_text_field_embedder.token_embedder_tokens.weight False
_highway_layer._module._layers.0.weight True
_highway_layer._module._layers.0.bias True
_highway_layer._module._layers.1.weight True
_highway_layer._module._layers.1.bias True
_phrase_layer._module.weight_ih_l0 True
_phrase_layer._module.weight_hh_l0 True
_phrase_layer._module.bias_ih_l0 True
_phrase_layer._module.bias_hh_l0 True
_phrase_layer._module.weight_ih_l0_reverse True
_phrase_layer._module.weight_hh_l0_reverse True
_phrase_layer._module.bias_ih_l0_reverse True
_phrase_layer._module.bias_hh_l0_reverse True
_matrix_attention._weight_vector True
_matrix_attention._bias True
_modeling_layer._module.weight_ih_l0 True
_modeling_layer._module.weight_hh_l0 True
_modeling_layer._module.bias_ih_l0 True
_modeling_layer._module.bias_hh_l0 True
_modeling_layer._module.weight_ih_l0_reverse True
_modeling_layer._module.weight_hh_l0_reverse True
_modeling_layer._module.bias_ih_l0_reverse True
_modeling_layer._module.bias_hh_l0_reverse True
_modeling_layer._module.weight_ih_l1 True
_modeling_layer._module.weight_hh_l1 True
_modeling_layer._module.bias_ih_l1 True
_modeling_layer._module.bias_hh_l1 True
_modeling_layer._module.weight_ih_l1_reverse True
_modeling_layer._module.weight_hh_l1_reverse True
_modeling_layer._module.bias_ih_l1_reverse True
_modeling_layer._module.bias_hh_l1_reverse True
_span_end_encoder._module.weight_ih_l0 True
_span_end_encoder._module.weight_hh_l0 True
_span_end_encoder._module.bias_ih_l0 True
_span_end_encoder._module.bias_hh_l0 True
_span_end_encoder._module.weight_ih_l0_reverse True
_span_end_encoder._module.weight_hh_l0_reverse True
_span_end_encoder._module.bias_ih_l0_reverse True
_span_end_encoder._module.bias_hh_l0_reverse True
_span_start_predictor._module.weight True
_span_start_predictor._module.bias True
_span_end_predictor._module.weight True
_span_end_predictor._module.bias True



52it [00:04, 13.45it/s]error occured, qas_id: 56d98a59dc89441400fdb52a instance number: 52
663it [00:54, 15.96it/s]error occured, qas_id: 56bec6ac3aeaaa14008c93fe instance number: 664
956it [01:26, 10.17it/s]error occured, qas_id: 573330444776f4190066075a instance number: 956
1322it [01:57, 12.99it/s]error occured, qas_id: 56dfb5f5231d4119001abcb8 instance number: 1322
1345it [02:00, 10.54it/s]error occured, qas_id: 56e057e1231d4119001ac044 instance number: 1346
1596it [02:20, 15.59it/s]error occured, qas_id: 56e11a73e3433e1400422bf1 instance number: 1598
1634it [02:25,  6.29it/s]error occured, qas_id: 56e12005cd28a01900c67618 instance number: 1635
2798it [04:24, 16.58it/s]error occured, qas_id: 570614ff52bb89140068988c instance number: 2798
4174it [06:50,  4.82it/s]error occured, qas_id: 572658435951b619008f7029 instance number: 4174
4179it [06:51,  3.33it/s]error occured, qas_id: 5726965ef1498d1400e8e488 instance number: 4179
4908it [08:21, 10.74it/s]error occured, qas_id: 572648d1708984140094c15e instance number: 4909
5257it [08:55,  9.75it/s]error occured, qas_id: 57267de1f1498d1400e8e195 instance number: 5257
5836it [10:00, 10.51it/s]error occured, qas_id: 57273b69dd62a815002e99d6 instance number: 5836
6145it [10:34, 14.58it/s]error occured, qas_id: 5726ab47f1498d1400e8e6a2 instance number: 6145
6360it [10:54, 12.89it/s]error occured, qas_id: 5726da89dd62a815002e92b4 instance number: 6360
6979it [11:51, 10.08it/s]error occured, qas_id: 5727526cdd62a815002e9b0f instance number: 6980
7050it [11:57, 11.04it/s]error occured, qas_id: 57274ca8dd62a815002e9aa6 instance number: 7051
7624it [12:53, 12.32it/s]error occured, qas_id: 572a2224af94a219006aa824 instance number: 7624
8205it [13:53, 10.19it/s]error occured, qas_id: 57286fa83acd2414000df9e8 instance number: 8205
8313it [14:05, 12.44it/s]error occured, qas_id: 5728827b2ca10214002da42b instance number: 8314
8556it [14:27,  5.83it/s]error occured, qas_id: 5729276c1d046914007790db instance number: 8556
8601it [14:33, 13.68it/s]error occured, qas_id: 57293d116aef051400154bc8 instance number: 8601
8793it [14:50, 12.32it/s]error occured, qas_id: 572969f51d046914007793df instance number: 8794
8925it [15:01,  9.65it/s]error occured, qas_id: 572975073f37b31900478419 instance number: 8926
9863it [16:28, 12.55it/s]error occured, qas_id: 57308f6b8ab72b1400f9c582 instance number: 9864

